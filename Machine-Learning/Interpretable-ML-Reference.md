> Written with [StackEdit](https://stackedit.io/).

## Interpretable Machine Learning References

- [Explainable AI in Fraud Detection â€“ A Back to the Future Story](https://www.fico.com/blogs/analytics-optimization/explainable-ai-fraud-detection/)
- [PyData Tel Aviv Meetup: Fraud Detection Challenges and Data Skepticism using LIME - Shir Meir Lador](https://www.youtube.com/watch?v=HcaAKI1tVGM)
- [Interpretable machine learning (part 1): Peeking into the black box](https://www.youtube.com/watch?v=SeRahnbWTtM)
- [Interpretable machine learning (part 2): ICE, partial dependency plots and surrogate models](https://www.youtube.com/watch?v=SFcAfoTcCVA)
- [Interpretable machine learning (part 3): Shapley values and packages for IML](https://www.youtube.com/watch?v=OiJGxA64bJs)
- [Interpretable Machine Learning](https://www.youtube.com/watch?v=3uLegw5HhYk)
- [Open the Black Box: an Introduction to Model Interpretability with LIME and SHAP - Kevin Lemagnen](https://www.youtube.com/watch?v=C80SQe16Rao)
- ["Why Should I Trust you?" Explaining the Predictions of Any Classifier](https://www.youtube.com/watch?v=KP7-JtFMLo4)
- [Interpretable Machine Learning Using LIME Framework - Kasia Kulma (PhD), Data Scientist, Aviva](https://www.youtube.com/watch?v=Y3t11vuuOM)
- [#How to improve your machine learning models by explaining predictions with LIME]()
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTAzMjI5NTc1MSwzMzk3OTY1MiwtMTQ0Nz
M3ODMyMl19
-->